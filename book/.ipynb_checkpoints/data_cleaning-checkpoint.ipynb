{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c6e504",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "The following notebook is for data cleaning and preparation. The dataset provided by {cite}`fitzgerald_morrin_holland_2021` represents GCMS analysis of VOCs from pure cultures of bacteria. The data is semi-structured in nature. It presents some challenges such as missing values. In the Excel file, the data obtained from the GCMS is presented in multiple formats, namely:\n",
    "1. Long\n",
    "2. Wide\n",
    "\n",
    "Both sheets represent the same data. We will be working with the '**Wide**' dataset. This is because features represented as columns work better for Google's AutoML Tables. There are various other sheets available in the Excel, but these serve no purpose for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c2c81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fcd39372",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(\"../data/wide_frontier.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74edf251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Strain</th>\n",
       "      <th>Samples</th>\n",
       "      <th>Ethyl Acetate</th>\n",
       "      <th>Ethanol</th>\n",
       "      <th>Propanoic acid, ethyl ester</th>\n",
       "      <th>2-Pentanone</th>\n",
       "      <th>Decane</th>\n",
       "      <th>Methyl Isobutyl Ketone</th>\n",
       "      <th>Amylene hydrate</th>\n",
       "      <th>...</th>\n",
       "      <th>1-Dodecanol</th>\n",
       "      <th>Methyl tetradecanoate</th>\n",
       "      <th>2-Pentadecanone</th>\n",
       "      <th>Tetradecanoic acid, ethyl ester</th>\n",
       "      <th>Hexadecanal</th>\n",
       "      <th>n-Tridecan-1-ol</th>\n",
       "      <th>1-Tetradecanol</th>\n",
       "      <th>n-Pentadecanol</th>\n",
       "      <th>1-Hexadecanol</th>\n",
       "      <th>Indole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SA</td>\n",
       "      <td>SA_A</td>\n",
       "      <td>SA.A_TSB_A</td>\n",
       "      <td>465374.0</td>\n",
       "      <td>1027715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1289650</td>\n",
       "      <td>800581</td>\n",
       "      <td>324424.0</td>\n",
       "      <td>73015</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SA</td>\n",
       "      <td>SA_A</td>\n",
       "      <td>SA.A_TSB_B</td>\n",
       "      <td>193151.0</td>\n",
       "      <td>1050974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>504113</td>\n",
       "      <td>294680</td>\n",
       "      <td>189630.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SA</td>\n",
       "      <td>SA_A</td>\n",
       "      <td>SA.A_TSB_C</td>\n",
       "      <td>403286.0</td>\n",
       "      <td>1850391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1169501</td>\n",
       "      <td>15</td>\n",
       "      <td>228163.0</td>\n",
       "      <td>73558</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SA</td>\n",
       "      <td>SA_A</td>\n",
       "      <td>SA.A_TSB_D</td>\n",
       "      <td>129833.0</td>\n",
       "      <td>5140770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1926072</td>\n",
       "      <td>124282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188367</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SA</td>\n",
       "      <td>SA_A</td>\n",
       "      <td>SA.A_TSB_E</td>\n",
       "      <td>117105.0</td>\n",
       "      <td>3422557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>246751</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species Strain    Samples    Ethyl Acetate  Ethanol  \\\n",
       "0      SA   SA_A  SA.A_TSB_A        465374.0  1027715   \n",
       "1      SA   SA_A  SA.A_TSB_B        193151.0  1050974   \n",
       "2      SA   SA_A  SA.A_TSB_C        403286.0  1850391   \n",
       "3      SA   SA_A  SA.A_TSB_D        129833.0  5140770   \n",
       "4      SA   SA_A  SA.A_TSB_E        117105.0  3422557   \n",
       "\n",
       "   Propanoic acid, ethyl ester  2-Pentanone  Decane  Methyl Isobutyl Ketone  \\\n",
       "0                          NaN      1289650  800581                324424.0   \n",
       "1                          NaN       504113  294680                189630.0   \n",
       "2                          NaN      1169501      15                228163.0   \n",
       "3                          NaN      1926072  124282                     0.0   \n",
       "4                          NaN       246751       0                     0.0   \n",
       "\n",
       "   Amylene hydrate  ...  1-Dodecanol  Methyl tetradecanoate   2-Pentadecanone  \\\n",
       "0            73015  ...          NaN                    NaN               NaN   \n",
       "1                0  ...          NaN                    NaN               NaN   \n",
       "2            73558  ...          NaN                    NaN               NaN   \n",
       "3           188367  ...          NaN                    NaN               NaN   \n",
       "4                0  ...          NaN                    NaN               NaN   \n",
       "\n",
       "   Tetradecanoic acid, ethyl ester  Hexadecanal  n-Tridecan-1-ol  \\\n",
       "0                              NaN          NaN              NaN   \n",
       "1                              NaN          NaN              NaN   \n",
       "2                              NaN          NaN              NaN   \n",
       "3                              NaN          NaN              NaN   \n",
       "4                              NaN          NaN              NaN   \n",
       "\n",
       "   1-Tetradecanol  n-Pentadecanol   1-Hexadecanol  Indole  \n",
       "0             NaN             NaN             NaN     NaN  \n",
       "1             NaN             NaN             NaN     NaN  \n",
       "2             NaN             NaN             NaN     NaN  \n",
       "3             NaN             NaN             NaN     NaN  \n",
       "4             NaN             NaN             NaN     NaN  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504b834c",
   "metadata": {},
   "source": [
    "## Null-Values\n",
    "In the given dataset, rows represent **species & strains** of bacterial micro-organisms. The columns represent individual chemical-compounds commonly found in the volatile organic compounds (VOCs). {cite:p}`fitzgerald2021` informs us that:\n",
    "* Cells with missing data represent a species-media specific combination in which the presence of that particular compound was never recorded.\n",
    "* Cells with the value 0 represent a species-media spcific combination in which the presence of that compound was found in some equivalent sample, but not this particular sample.\n",
    "\n",
    "Because of this knowledge, it is difficult to understand what should be done with the missing values. According to the Google Cloud Platform documentation for ['Best Practices for creating training data'](https://cloud.google.com/automl-tables/docs/data-best-practices#avoid_missing_values_where_possible), it is best to avoid missing values where possible. Values can be left missing if the column is set to be nullable.\n",
    "\n",
    "[**TPOT**](http://epistasislab.github.io/tpot/) is an Automatic Machine Learning package in Python. In this particular case, using TPOT will prove more beneficial to us and will allow us more control. As of *Version 0.9* TPOT supports sparse matrices with a new built-in TPOT configuration \"TPOT sparse\". So, for us to support the use of missing values, we must use this particular configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993a2501",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "We must ensure that the target variable is also presented as an integer. To do this, we use SKLearns label encoder. This creates a 1 to 1 mapping between the target values and integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7f552f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EC_A', 'EC_B', 'PA_A', 'PA_B', 'SA_A', 'SA_B']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(raw.Strain)\n",
    "list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9829c900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 2, 3, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.Strain = le.transform(raw.Strain)\n",
    "raw.Strain.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c23e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.to_csv('../data/cleaned/long.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2539af",
   "metadata": {},
   "source": [
    "## Seperate By Media\n",
    "Let's divide the dataset by media to perform per-media analysis of clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e0602b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled = raw.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60886d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsb = filled[filled['Samples '].str.contains(\"TSB\")]\n",
    "bhi = filled[filled['Samples '].str.contains(\"BHI\")]\n",
    "lb = filled[filled['Samples '].str.contains(\"LB\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f34b409",
   "metadata": {},
   "source": [
    "## Standardization\n",
    "We will be performing PCA for feature reduction. This will allow us to better cluster the data later on. The sklearn implimentation of PCA does not handle NaN values. We will let all NaN values equal 0 to perform PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "997bb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsb_features = tsb.iloc[:,3:]\n",
    "bhi_features = bhi.iloc[:,3:]\n",
    "lb_features = lb.iloc[:,3:]\n",
    "full_features = filled.iloc[:,3:]\n",
    "\n",
    "x1 = StandardScaler().fit_transform(tsb_features)\n",
    "x2 = StandardScaler().fit_transform(bhi_features)\n",
    "x3 = StandardScaler().fit_transform(lb_features)\n",
    "x4 = StandardScaler().fit_transform(full_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599583c",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a569d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's perform PCA\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x4)\n",
    "principalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc936cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's rejoin the columns describing the data\n",
    "pca_tsb = pd.concat([principalDf, tsb[['Species', 'Strain', 'Samples ']].reset_index(drop=True)], axis = 1)\n",
    "pca_bhi = pd.concat([principalDf, bhi[['Species', 'Strain', 'Samples ']].reset_index(drop=True)], axis = 1)\n",
    "pca_lb = pd.concat([principalDf, lb[['Species', 'Strain', 'Samples ']].reset_index(drop=True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f221a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_full = pd.concat([principalDf, filled[['Species', 'Strain', 'Samples ']].reset_index(drop=True)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f381695e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's write out our datta\n",
    "pca_tsb.to_csv('../data/cleaned/tsb_components.csv', index=False)\n",
    "pca_bhi.to_csv('../data/cleaned/bhi_components.csv', index=False)\n",
    "pca_lb.to_csv('../data/cleaned/lb_components.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0695001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_full.to_csv('../data/cleaned/full_components.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
